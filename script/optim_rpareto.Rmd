---
title: "Optimisation with the r-pareto process"
author: " "
date: "`r Sys.Date()`" 
output:
  pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 7, fig.height = 7,
                      fig.align = 'center', message = FALSE, warning = FALSE,
                      fig.pos = 'H')
par(cex.main = 0.8,
    cex.lab = 0.7,
    cex.axis = 0.6)
```


```{r lib, echo=FALSE}
# setwd("./script")
# devtools::uninstall("../../generain")
# devtools::install("../../generain")

library(generain)
library(reshape2)
library(ggplot2)
source("load_libraries.R")
library(kableExtra)
library(extRemes)
library(bbmle)
library(ismev)
library(extRemes)
library(evd)
```

# Simulation of rpareto process

Risk function $r(X_{s, t}) = X_{s_0, t_0}$.

```{r rparetosim, fig.width = 5, fig.height = 5}
adv <- c(0.5, 0.3)
params <- c(0.4, 0.2, 1, 1.2) # ok verif sur simu
true_param <- c(params, adv)
beta1 <- 0.4
beta2 <- 0.2
alpha1 <- 1.5
alpha2 <- 1
ngrid <- 5
spa <- 1:ngrid
nsites <- ngrid^2 # if the grid is squared
temp <- 1:30

# Conditional point
s0 <- c(1, 1)
t0 <- 1

# Number of realizations
nres <- 100

# Simulate the process
# simu <- sim_rpareto(beta1, beta2, alpha1, alpha2, spa, spa, temp, adv, s0,
#                     t0, nres)

adv_int <- adv * 10
adv_str <- sprintf("%02d_%02d", adv_int[1], adv_int[2])

# Save the data
foldername <- paste0("../data/simulations_rpar/sim_", ngrid^2, "s_",
                                length(temp), "t_", adv_str, "/")


if (!dir.exists(foldername)) {
  dir.create(foldername, recursive = TRUE)
}

# save_simulations(simu, ngrid, nres, folder = foldername,
#         file = paste0("rpar_", ngrid^2, "s_", length(temp), "t"))


list_simu <- list()
for (i in 1:nres) {
  file_name <- paste0(foldername, "rpar_", ngrid^2, "s_",
                        length(temp), "t_", i, ".csv")
  list_simu[[i]] <- read.csv(file_name)
}

# Plot the first realization
simu_df <- list_simu[[1]]
par(mfrow = c(2, 2))
plot(simu_df$S1, main = "S1")
plot(simu_df$S2, main = "S2")
plot(simu_df$S3, main = "S3")
plot(simu_df$S4, main = "S4")
```


```{r rpargif, fig.width = 5, fig.height = 5}
library(animation)
create_simu_gif(simu_df, true_param, "rpar", forcedtemp = 30)
```

# Get conditional lag vectors

```{r lagvec, fig.width = 5, fig.height = 5}
sites_coords <- generate_grid_coords(ngrid)
df_lags <- get_conditional_lag_vectors(sites_coords, true_param, s0, t0,
                                       hmax = sqrt(17), tau_vect = 0:10)
head(df_lags)
```

# Optimisation of variogram parameters

```{r negll, echo=FALSE}
neg_ll <- function(params, data, df_lags, locations, quantile, excesses,
                   latlon = FALSE, hmax = NA, s0 = NA, t0 = NA, pmarg = NA,
                   threshold = FALSE) {
  if (is.na(hmax)) {
    hmax <- max(df_lags$hnorm) # maximum spatial lag
  }
  tau <- unique(df_lags$tau) # unique temporal lags

  # advection parameters
  adv <- if (length(params) == 6) params[5:6] else c(0, 0)
  # get the index of the conditioning site s0
  ind_s0 <- if (all(is.na(s0))) 1 else which(locations$Latitude == s0[1] &&
                                             locations$Longitude == s0[2])

  # Bounds for the parameters
  lower.bound <- c(1e-6, 1e-6, 1e-6, 1e-6)
  upper.bound <- c(Inf, Inf, 1.999, 1.999)
  if (length(params) == 6) {
    lower.bound <- c(lower.bound, -Inf, -Inf)
    upper.bound <- c(upper.bound, Inf, Inf)
  }

  # Check if the parameters are in the bounds
  if (any(params < lower.bound) || any(params > upper.bound)) {
    return(1e50)
  }

  if (!all(adv == c(0, 0))) { # if we have the advection parameters
    # then the lag vectors are different
    if (is.na(s0) && is.na(t0)) {
      df_lags <- get_lag_vectors(locations, params, hmax = hmax, tau_vect = tau)
    } else { # else we have to consider the conditioning location and time
      df_lags <- get_conditional_lag_vectors(locations, params, hmax = hmax,
                                       tau_vect = tau, s0 = s0, t0 = t0)
      excesses <- empirical_excesses(data, quantile, df_lags, threshold) # TODO: to remove if possible
    }
  }

  # number of marginal excesses
  nmarg <- get_marginal_excess(data, quantile, ind_s0, t0, threshold)
  Tmax <- if (is.na(t0)) nrow(data) else nrow(data) + 1 - t0
  if (is.na(pmarg)) {
    p <- nmarg / Tmax # probability of marginal excesses
  } else {
    p <- pmarg
  }
  chi <- theorical_chi(params, df_lags) # get chi matrix
  ll_df <- excesses
  ll_df$Tobs <- Tmax - ll_df$tau # number of possible excesses
  ll_df$chi <- chi$chi
  ll_df$chi <- ifelse(ll_df$chi <= 0, 1e-10, ll_df$chi)
  ll_df$pchi <- 1 - p * ll_df$chi

  ll_df$non_excesses <- ll_df$Tobs - ll_df$kij # number of non-excesses
  ll_df$ll <- ll_df$kij * log(ll_df$chi) +
              ll_df$non_excesses * log(ll_df$pchi)

  nll <- -sum(ll_df$ll, na.rm = TRUE)
  return(nll)
}

neg_ll_par <- function(beta1, beta2, alpha1, alpha2, adv1, adv2,
                   data, df_lags, locations, quantile, excesses,
                   latlon = FALSE, hmax = NA, s0 = NA, t0 = NA, pmarg = NA) {
  params <- c(beta1, beta2, alpha1, alpha2, adv1, adv2)
  adv <- c(adv1, adv2)
  if (is.na(hmax)) {
    hmax <- max(df_lags$hnorm) # maximum spatial lag
  }
  print(params)
  tau <- unique(df_lags$tau) # unique temporal lags

  # advection parameters
  adv <- if (length(params) == 6) params[5:6] else c(0, 0)
  # get the index of the conditioning site s0
  ind_s0 <- if (all(is.na(s0))) 1 else which(locations$Latitude == s0[1] &&
                                             locations$Longitude == s0[2])

  # Bounds for the parameters
  lower.bound <- c(1e-6, 1e-6, 1e-6, 1e-6)
  upper.bound <- c(Inf, Inf, 1.999, 1.999)
  if (length(params) == 6) {
    lower.bound <- c(lower.bound, -Inf, -Inf)
    upper.bound <- c(upper.bound, Inf, Inf)
  }

  # Check if the parameters are in the bounds
  if (any(params < lower.bound) || any(params > upper.bound)) {
    return(1e50)
  }

  if (!all(adv == c(0, 0))) { # if we have the advection parameters
    # then the lag vectors are different
    if (is.na(s0) && is.na(t0)) {
      df_lags <- get_lag_vectors(locations, params, hmax = hmax, tau_vect = tau)
    } else { # else we have to consider the conditioning location and time
      df_lags <- get_conditional_lag_vectors(locations, params, hmax = hmax,
                                       tau_vect = tau, s0 = s0, t0 = t0)
      excesses <- empirical_excesses(data, quantile, df_lags) # TODO: to remove if possible
    }
  }

  # number of marginal excesses
  nmarg <- get_marginal_excess(data, quantile, ind_s0, t0)
  Tmax <- if (is.na(t0)) nrow(data) else nrow(data) + 1 - t0
  if (is.na(pmarg)) {
    p <- nmarg / Tmax # probability of marginal excesses
  } else {
    p <- pmarg
  }
  chi <- theorical_chi(params, df_lags) # get chi matrix
  ll_df <- excesses
  ll_df$Tobs <- Tmax - ll_df$tau # number of possible excesses
  ll_df$chi <- chi$chi
  ll_df$chi <- ifelse(ll_df$chi <= 0, 1e-10, ll_df$chi)
  ll_df$pchi <- 1 - p * ll_df$chi

  ll_df$non_excesses <- ll_df$Tobs - ll_df$kij # number of non-excesses
  ll_df$ll <- ll_df$kij * log(ll_df$chi) +
              ll_df$non_excesses * log(ll_df$pchi)

  nll <- -sum(ll_df$ll, na.rm = TRUE)
  return(nll)
}
```

```{r optim, fig.width = 5, fig.height = 5}
# Optimisation of the variogram parameters
q_values <- c(1, 1.1, 1.2)

result_table <- data.frame(q = numeric(), beta1 = numeric(), beta2 = numeric(),
                           alpha1 = numeric(), alpha2 = numeric(),
                           adv1 = numeric(), adv2 = numeric())

df_lags <- get_conditional_lag_vectors(sites_coords, true_param, s0, t0,
                                       hmax = sqrt(17), tau_vect = 0:10)
# For each quantile
for (q in q_values) {
  # Get the empirical excesses
  excesses <- empirical_excesses(simu_df, quantile = q, df_lags = df_lags,
                                threshold = TRUE)
  n_marg <- get_marginal_excess(simu_df, q, 1, 1, threshold = TRUE)
  pmarg <- n_marg / nrow(simu_df)
  # Optimization
  result <- optim(par = true_param, fn = neg_ll,
                  data = simu_df,
                  quantile = q,
                  df_lags = df_lags,
                  excesses = excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  s0 = s0,
                  t0 = t0,
                  threshold = TRUE,
                  method = "BFGS",
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000))

    res <- mle2(neg_ll_par,
              start = list(beta1 = true_param[1],
                           beta2 = true_param[2],
                           alpha1 = true_param[3],
                           alpha2 = true_param[4],
                           adv1 = true_param[5],
                           adv2 = true_param[6]),
              data = list(data = simu_df,
                          quantile = q,
                          df_lags = df_lags,
                          locations = sites_coords,
                          excesses = excesses,
                          s0 = s0,
                          t0 = t0,
                          method = "CG"),
              control = list(maxit = 10000),
              fixed = list(beta2 = 0.2))


  # Check convergence
  if (result$convergence == 0) {
    result_table <- rbind(result_table,
                          data.frame(q = q,
                                     beta1 = result$par[1],
                                     beta2 = result$par[2],
                                     alpha1 = result$par[3],
                                     alpha2 = result$par[4],
                                     adv1 = result$par[5],
                                     adv2 = result$par[6]))
  } else {
    # In case of non-convergence, store NAs
    result_table <- rbind(result_table,
        data.frame(q = q, beta1 = NA, beta2 = NA, alpha1 = NA, alpha2 = NA,
                   adv1 = NA, adv2 = NA))
  }
}

result_table <- round(result_table, 5)
df_rmse <- data.frame(q = result_table$q,
                rmse_beta1 = sqrt((result_table$beta1 - true_param[1])^2),
                rmse_beta2 = sqrt((result_table$beta2 - true_param[2])^2),
                rmse_alpha1 = sqrt((result_table$alpha1 - true_param[3])^2),
                rmse_alpha2 = sqrt((result_table$alpha2 - true_param[4])^2),
                rmse_adv1 = sqrt((result_table$adv1 - true_param[5])^2),
                rmse_adv2 = sqrt((result_table$adv2 - true_param[6])^2))

kable(result_table, "latex", booktabs = TRUE,
      caption = "Optim estimations for each quantile for one simulation")  %>%
  kable_styling(latex_options = "H",
    bootstrap_options = c("striped", "hover", "condensed", "responsive"))


kable(df_rmse, "latex", booktabs = TRUE,
      caption = "RMSE for each parameter and 
                  different quantiles for one simulation")  %>%
  kable_styling(latex_options = "H",
     bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


# Combining simulations together

```{r comb, fig.width = 5, fig.height = 5}
neg_ll_composite <- function(params, list_simu, df_lags, locations, quantile,
                    list_excesses, latlon = FALSE, hmax = NA, s0 = NA,
                    t0 = NA, threshold = FALSE) {
  ind_s0 <- which(locations$Latitude == s0[1] && locations$Longitude == s0[2])
  data <- do.call(rbind, list_simu)
  nmarg <- get_marginal_excess(data, quantile, ind_s0, t0, threshold)
  pmarg <- nmarg / nrow(data)
  nll_composite <- 0 # composite negative log-likelihood
  print(params)

  # Bounds for the parameters
  lower.bound <- c(1e-6, 1e-6, 1e-6, 1e-6)
  upper.bound <- c(Inf, Inf, 1.999, 1.999)
  if (length(params) == 6) {
    lower.bound <- c(lower.bound, -Inf, -Inf)
    upper.bound <- c(upper.bound, Inf, Inf)
  }

  # Check if the parameters are in the bounds
  if (any(params < lower.bound) || any(params > upper.bound)) {
    return(1e50)
  }

  nsample <- length(list_simu)
  for (i in 1:nsample) {
    # extract simulation data from i-th simulation
    simu <- list_simu[[i]]
    excesses <- list_excesses[[i]]
    nll_i <- neg_ll(params, simu, df_lags, locations, quantile,
                    latlon = latlon, hmax = hmax,
                    excesses = excesses, s0 = s0, t0 = t0, pmarg = pmarg,
                    threshold = threshold)
    nll_composite <- nll_composite + nll_i
  }
  print(nll_composite)
  return(nll_composite)
}

# Combine all simulations
simu_all <- do.call(rbind, list_simu)

# plot simu for 4 sites
par(mfrow = c(2, 2))
plot(simu_all$S1, main = "S1")
plot(simu_all$S2, main = "S2")
plot(simu_all$S10, main = "S10")
plot(simu_all$S11, main = "S11")

df_lags <- get_conditional_lag_vectors(sites_coords, true_param, s0, t0,
                                       hmax = sqrt(17), tau_vect = 0:10)

u <- 1
list_excesses <- list()
for (i in 1:nres) {
  list_excesses[[i]] <- empirical_excesses(list_simu[[i]], u, df_lags,
                                           threshold = TRUE)
}

result <- optim(par = c(true_param), fn = neg_ll_composite,
                  list_simu = list_simu,
                  quantile = u,
                  df_lags = df_lags,
                  list_excesses = list_excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  s0 = s0,
                  t0 = t0,
                  threshold = TRUE,
                  method = "CG",
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000))

df_result <- data.frame(beta1 =  result$par[1],
                        beta2 = result$par[2],
                        alpha1 = result$par[3],
                        alpha2 = result$par[4],
                        adv1 = result$par[5],
                        adv2 = result$par[6])

df_rmse <- data.frame(beta1 = sqrt((result$par[1] - true_param[1])^2),
                beta2 = sqrt((result$par[2] - true_param[2])^2),
                alpha1 = sqrt((result$par[3] - true_param[3])^2),
                alpha2 = sqrt((result$par[4] - true_param[4])^2),
                adv1 = sqrt((result$par[5] - true_param[5])^2),
                adv2 = sqrt((result$par[6] - true_param[6])^2))

df_result <- rbind(df_result, df_rmse)
rownames(df_result) <- c("estim", "rmse")
kable(df_result, "latex", booktabs = TRUE,
        caption = "RMSE for all simulations together")  %>%
    kable_styling(latex_options = "H",
        bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


## R-Pareto without advection


```{r rparetosimnoadv, fig.width = 5, fig.height = 5}
adv <- c(0, 0)
params <- c(0.4, 0.2, 1, 1.2) # ok verif sur simu
true_param <- c(params, adv)
beta1 <- 0.4
beta2 <- 0.2
alpha1 <- 1.5
alpha2 <- 1
ngrid <- 5
spa <- 1:ngrid
nsites <- ngrid^2 # if the grid is squared
temp <- 1:30

# Conditional point
s0 <- c(1, 1)
t0 <- 1

# Number of realizations
nres <- 100

# Simulate the process
simu <- sim_rpareto(beta1, beta2, alpha1, alpha2, spa, spa, temp, adv, s0,
                    t0, nres)

adv_int <- adv * 10
adv_str <- sprintf("%02d_%02d", adv_int[1], adv_int[2])

# Save the data
foldername <- paste0("../data/simulations_rpar/sim_", ngrid^2, "s_",
                                length(temp), "t_", adv_str, "/")


if (!dir.exists(foldername)) {
  dir.create(foldername, recursive = TRUE)
}

save_simulations(simu, ngrid, nres, folder = foldername,
        file = paste0("rpar_", ngrid^2, "s_", length(temp), "t"))


list_simu <- list()
for (i in 1:nres) {
    file_name <- paste0(foldername, "rpar_", ngrid^2, "s_",
                        length(temp), "t_", i, ".csv")
  list_simu[[i]] <- read.csv(file_name)
}

# Plot the first realization on same scale
simu_df <- list_simu[[1]]
par(mfrow = c(2, 2))
max_all <- max(simu_df$S1, simu_df$S2, simu_df$S3, simu_df$S10)
min_all <- min(simu_df$S1, simu_df$S2, simu_df$S3, simu_df$S10)
plot(simu_df$S1, main = "S1", ylim = c(min_all, max_all))
plot(simu_df$S2, main = "S2", ylim = c(min_all, max_all))
plot(simu_df$S3, main = "S3", ylim = c(min_all, max_all))
plot(simu_df$S10, main = "S10", ylim = c(min_all, max_all))
```

```{r optimrparnoadv}
# Combine all simulations
simu_all <- do.call(rbind, list_simu)

# plot simu for 4 sites
par(mfrow = c(2, 2))
plot(simu_all$S1, main = "S1")
plot(simu_all$S2, main = "S2")
plot(simu_all$S10, main = "S10")
plot(simu_all$S11, main = "S11")

df_lags <- get_conditional_lag_vectors(sites_coords, true_param, s0, t0,
                                       hmax = sqrt(17), tau_vect = 0:10)

u <- 1
list_excesses <- list()
for (i in 1:nres) {
  list_excesses[[i]] <- empirical_excesses(list_simu[[i]], u, df_lags,
                                           threshold = TRUE)
}

result <- optim(par = c(true_param), fn = neg_ll_composite,
                  list_simu = list_simu,
                  quantile = u,
                  df_lags = df_lags,
                  list_excesses = list_excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  s0 = s0,
                  t0 = t0,
                  threshold = TRUE,
                  method = "CG",
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000))

df_result <- data.frame(beta1 =  result$par[1],
                        beta2 = result$par[2],
                        alpha1 = result$par[3],
                        alpha2 = result$par[4],
                        adv1 = result$par[5],
                        adv2 = result$par[6])

df_rmse <- data.frame(beta1 = sqrt((result$par[1] - true_param[1])^2),
                beta2 = sqrt((result$par[2] - true_param[2])^2),
                alpha1 = sqrt((result$par[3] - true_param[3])^2),
                alpha2 = sqrt((result$par[4] - true_param[4])^2),
                adv1 = sqrt((result$par[5] - true_param[5])^2),
                adv2 = sqrt((result$par[6] - true_param[6])^2))

df_result <- rbind(df_result, df_rmse)
rownames(df_result) <- c("estim", "rmse")
kable(df_result, "latex", booktabs = TRUE,
        caption = "RMSE for all simulations together")  %>%
    kable_styling(latex_options = "H",
        bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


## Retour sur les simulations de Brown-Resnick 

### Sans advection

```{r simBR, fig.width = 5, fig.height = 5}
adv <- c(0, 0)
true_param <- c(0.4, 0.2, 1.5, 1) # ok verif sur simu
ngrid <- 5
spa <- 1:ngrid
nsites <- ngrid^2 # if the grid is squared
temp <- 1:300

# get folder name
if (all(adv == c(0, 0))) {
    foldername <- paste0("../data/simulations_BR/sim_", ngrid^2, "s_",
                                length(temp), "t/")
} else {
    adv_int <- adv * 10
    adv_str <- sprintf("%02d%02d", adv_int[1], adv_int[2])

    # Save the data
    foldername <- paste0("../data/simulations_BR/sim_", ngrid^2, "s_",
                                    length(temp), "t_adv_", adv_str, "/")

}

# get number of files in the folder
nfiles <- length(list.files(foldername))

# load simulated data in a list
simu_list <- list()

for(i in 1:nfiles) {
    file_path <- paste0(foldername, "br_", ngrid^2, "s_", length(temp), "t_", i,
                        ".csv")
    simu_temp <- read.csv(file_path)
    simu_list[[i]] <- simu_temp
}

simu_df <- simu_list[[1]]
nsites <- ncol(simu_df)
sites_coords <- generate_grid_coords(sqrt(nsites))
```


```{r, echo=FALSE}
# plot the simulations
par(mfrow = c(2, 2), cex = 0.5, main = "Simulated data")
plot(simu_df[, 1], main = "Site 1")
plot(simu_df[, 2], main = "Site 2")
plot(simu_df[, 3], main = "Site 3")
plot(simu_df[, 4], main = "Site 4")
```

```{r optimBR, fig.width = 5, fig.height = 5}
# Optimisation of the variogram parameters
q_values <- seq(0.80, 0.95, 0.005)

df_lags <- get_lag_vectors(sites_coords, true_param, hmax = sqrt(17),
                           tau_vect = 0:10)
                           
result_table <- data.frame(q = numeric(), beta1 = numeric(), beta2 = numeric(),
                           alpha1 = numeric(), alpha2 = numeric())

# For each quantile
for (q in q_values) {
  # Get the empirical excesses
  excesses <- empirical_excesses(simu_df, quantile = q, df_lags = df_lags)

  # Optimization
  result <- optim(par = c(true_param), fn = neg_ll,
                  data = simu_df,
                  quantile = q,
                  df_lags = df_lags,
                  excesses = excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  method = "BFGS",
                  control = list(parscale = c(1, 1, 1, 1),
                                 maxit = 10000))

  # Check convergence
  if (result$convergence == 0) {
    result_table <- rbind(result_table,
                          data.frame(q = q,
                                     beta1 = result$par[1],
                                     beta2 = result$par[2],
                                     alpha1 = result$par[3],
                                     alpha2 = result$par[4]))
  } else {
    # In case of non-convergence, store NAs
    result_table <- rbind(result_table,
        data.frame(q = q, beta1 = NA, beta2 = NA, alpha1 = NA, alpha2 = NA))
  }
}

result_table <- round(result_table, 5)
df_rmse <- data.frame(q = result_table$q,
                rmse_beta1 = sqrt((result_table$beta1 - true_param[1])^2),
                rmse_beta2 = sqrt((result_table$beta2 - true_param[2])^2),
                rmse_alpha1 = sqrt((result_table$alpha1 - true_param[3])^2),
                rmse_alpha2 = sqrt((result_table$alpha2 - true_param[4])^2))

kable(result_table, "latex", booktabs = TRUE,
      caption = "Optim estimations for each quantile for one simulation")  %>%
  kable_styling(latex_options = "H",
    bootstrap_options = c("striped", "hover", "condensed", "responsive"))


kable(df_rmse, "latex", booktabs = TRUE,
      caption = "RMSE for each parameter and 
                  different quantiles for one simulation")  %>%
  kable_styling(latex_options = "H",
     bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```



```{r optimBR2, fig.width = 5, fig.height = 5}
# Optimisation of the variogram parameters
q_values <- seq(0.9, 0.95, 0.005)

df_lags <- get_lag_vectors(sites_coords, true_param, hmax = sqrt(17),
                           tau_vect = 0:10)
                           
result_table <- data.frame(q = numeric(), beta1 = numeric(), beta2 = numeric(),
                           alpha1 = numeric(), alpha2 = numeric(),
                           adv1 = numeric(), adv2 = numeric())

# For each quantile
for (q in q_values) {
  # Get the empirical excesses
  excesses <- empirical_excesses(simu_df, quantile = q, df_lags = df_lags)

  # Optimization
  result <- optim(par = c(true_param, adv), fn = neg_ll,
                  data = simu_df,
                  quantile = q,
                  df_lags = df_lags,
                  excesses = excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  method = "BFGS",
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000))

  # Check convergence
  if (result$convergence == 0 || result$value == 1e50) {
    result_table <- rbind(result_table,
                          data.frame(q = q,
                                     beta1 = result$par[1],
                                     beta2 = result$par[2],
                                     alpha1 = result$par[3],
                                     alpha2 = result$par[4],
                                     adv1 = result$par[5],
                                     adv2 = result$par[6]))
  } else {
    # In case of non-convergence, store NAs
    result_table <- rbind(result_table,
        data.frame(q = q, beta1 = NA, beta2 = NA, alpha1 = NA, alpha2 = NA,
                   adv1 = NA, adv2 = NA))
  }
}

result_table <- round(result_table, 5)
df_rmse <- data.frame(q = result_table$q,
                rmse_beta1 = sqrt((result_table$beta1 - true_param[1])^2),
                rmse_beta2 = sqrt((result_table$beta2 - true_param[2])^2),
                rmse_alpha1 = sqrt((result_table$alpha1 - true_param[3])^2),
                rmse_alpha2 = sqrt((result_table$alpha2 - true_param[4])^2),
                rmse_adv1 = sqrt((result_table$adv1 - adv[1])^2),
                rmse_adv2 = sqrt((result_table$adv2 - adv[2])^2))

kable(result_table, "latex", booktabs = TRUE,
      caption = "Optim estimations for each quantile for one simulation")  %>%
  kable_styling(latex_options = "H",
    bootstrap_options = c("striped", "hover", "condensed", "responsive"))


kable(df_rmse, "latex", booktabs = TRUE,
      caption = "RMSE for each parameter and 
                  different quantiles for one simulation")  %>%
  kable_styling(latex_options = "H",
     bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

### Avec advection

```{r simBRadv, fig.width = 5, fig.height = 5}
adv <- c(0.5, 0.8)
true_param <- c(0.4, 0.2, 1.5, 1, adv) # ok verif sur simu
ngrid <- 5
spa <- 1:ngrid
nsites <- ngrid^2 # if the grid is squared
temp <- 1:300

# get folder name
if (all(adv == c(0, 0))) {
    foldername <- paste0("../data/simulations_BR/sim_", ngrid^2, "s_",
                                length(temp), "t/")
} else {
    adv_int <- adv * 10
    adv_str <- sprintf("%02d%02d", adv_int[1], adv_int[2])

    # Save the data
    foldername <- paste0("../data/simulations_BR/sim_", ngrid^2, "s_",
                                    length(temp), "t_adv_", adv_str, "/")

}

# get number of files in the folder
nfiles <- length(list.files(foldername))

# load simulated data in a list
simu_list <- list()

for(i in 1:nfiles) {
    file_path <- paste0(foldername, "br_", ngrid^2, "s_", length(temp), "t_", i,
                        ".csv")
    simu_temp <- read.csv(file_path)
    simu_list[[i]] <- simu_temp
}

simu_df <- simu_list[[1]]
nsites <- ncol(simu_df)
sites_coords <- generate_grid_coords(sqrt(nsites))
```


```{r, echo=FALSE}
# plot the simulations
par(mfrow = c(2, 2), cex = 0.5, main = "Simulated data")
plot(simu_df[, 1], main = "Site 1")
plot(simu_df[, 2], main = "Site 2")
plot(simu_df[, 3], main = "Site 3")
plot(simu_df[, 4], main = "Site 4")
```

```{r optimBRadv, fig.width = 5, fig.height = 5}
# Optimisation of the variogram parameters
q_values <- seq(0.80, 0.95, 0.01)

df_lags <- get_lag_vectors(sites_coords, true_param, hmax = sqrt(17),
                           tau_vect = 0:10)
                           
result_table <- data.frame(q = numeric(), beta1 = numeric(), beta2 = numeric(),
                           alpha1 = numeric(), alpha2 = numeric(),
                           adv1 = numeric(), adv2 = numeric())

# For each quantile
for (q in q_values) {
  # Get the empirical excesses
  excesses <- empirical_excesses(simu_df, quantile = q, df_lags = df_lags)

  # Optimization
  result <- optim(par = c(true_param), fn = neg_ll,
                  data = simu_df,
                  quantile = q,
                  df_lags = df_lags,
                  excesses = excesses,
                  locations = sites_coords,
                  hmax = sqrt(17),
                  method = "CG",
                  control = list(parscale = c(1, 1, 0.1, 0.1, 1, 1),
                                 maxit = 10000))

  # Check convergence
  if (result$convergence == 0) {
    result_table <- rbind(result_table,
                          data.frame(q = q,
                                     beta1 = result$par[1],
                                     beta2 = result$par[2],
                                     alpha1 = result$par[3],
                                     alpha2 = result$par[4],
                                     adv1 = result$par[5],
                                     adv2 = result$par[6]))
  } else {
    # In case of non-convergence, store NAs
    result_table <- rbind(result_table,
        data.frame(q = q, beta1 = NA, beta2 = NA, alpha1 = NA, alpha2 = NA,
                   adv1 = NA, adv2 = NA))
  }
}

result_table <- round(result_table, 5)
df_rmse <- data.frame(q = result_table$q,
                rmse_beta1 = sqrt((result_table$beta1 - true_param[1])^2),
                rmse_beta2 = sqrt((result_table$beta2 - true_param[2])^2),
                rmse_alpha1 = sqrt((result_table$alpha1 - true_param[3])^2),
                rmse_alpha2 = sqrt((result_table$alpha2 - true_param[4])^2),
                rmse_adv1 = sqrt((result_table$adv1 - true_param[5])^2),
                rmse_adv2 = sqrt((result_table$adv2 - true_param[6])^2))

kable(result_table, "latex", booktabs = TRUE,
      caption = "Optim estimations for each quantile for one simulation")  %>%
  kable_styling(latex_options = "H",
    bootstrap_options = c("striped", "hover", "condensed", "responsive"))


kable(df_rmse, "latex", booktabs = TRUE,
      caption = "RMSE for each parameter and 
                  different quantiles for one simulation")  %>%
  kable_styling(latex_options = "H",
     bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```


