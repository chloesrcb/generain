---
title: "Model on Montpellier rainfall"
author: " "
date: "`r Sys.Date()`" 
output:
  pdf_document:
    extra_dependencies: ["float"]
    encoding: "UTF-8"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 7, fig.height = 7,
                      fig.align = 'center', message = FALSE, warning = FALSE,
                      fig.pos='H')
par(cex.main = 0.8,
    cex.lab = 0.7,
    cex.axis = 0.6)
```


```{r lib, echo=FALSE}
# setwd("./script")
library(generain)
library(reshape2)
library(ggplot2)
source("load_libraries.R")
library(kableExtra)
library(extRemes)
library(bbmle)
library(ismev)
library(extRemes)
library(evd)
library(latex2exp)
library(geosphere)

btf_theme <- theme_minimal() +
  theme(axis.text.x = element_text(size =  6, angle = 0),
        axis.text.y = element_text(size = 6),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text = element_text(size = 6),
        title = element_text(size = 10),
        axis.line = element_blank(),  # Remove axis lines
        panel.border = element_blank(),  # Remove plot border
        panel.background = element_rect(fill = "transparent", color = NA),
        # Remove plot background
        axis.text = element_blank(),  # Remove axis text
        axis.ticks = element_blank(),  # Remove axis ticks
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.grid = element_line(color = "#5c595943"))

# my green color
btfgreen <- "#69b3a2"
```

```{r}
################################################################################
# LOCATION ---------------------------------------------------------------------
################################################################################
# get location of each rain gauge
setwd("./script")
location_gauges <- read.csv("../data/PluvioMontpellier_1min/pluvio_mtp_loc.csv")
location_gauges$codestation <- c("iem", "mse", "poly", "um", "cefe", "cnrs",
                                 "crbm", "archiw", "archie", "um35", "chu1",
                                 "chu2", "chu3", "chu4", "chu5", "chu6", "chu7")

# Get distances matrix
dist_mat <- get_dist_mat(location_gauges)
df_dist <- reshape_distances(dist_mat)

################################################################################
# DATA -------------------------------------------------------------------------
################################################################################
# get rain measurements
# load data
load("../data/PluvioMontpellier_1min/rain_mtp_5min_2019_2022.RData")
rain <- rain.all5[c(1, 6:ncol(rain.all5))]
```


```{r}
# spatial structure with an almost constant amount of pairs in each intervals
df_dist_order <- df_dist[order(df_dist$value), ]
num_intervals <- 10
quantiles_rad <- quantile(df_dist_order$value,
                            probs = seq(0, 1, length.out = num_intervals + 1))
radius_intervals <- unique(quantiles_rad)
radius <- as.integer(radius_intervals)
radius[length(radius)] <- 1550
dist_counts <- table(cut(df_dist$value, breaks = radius))

# Get dataframe for the histogram plot
df_hist <- data.frame(dist_counts)

colnames(df_hist) <- c("Interval", "Count")

df_hist$Breaks <- gsub("e\\+0.", "0", df_hist$Interval)
df_hist$Breaks <- gsub("\\.", "", df_hist$Breaks)

# # Histogram
histradius <- ggplot(df_hist, aes(x = Interval, y = Count)) +
  btf_theme +
  geom_bar(stat = "identity", fill = btfgreen, alpha = 0.8) +
  xlab("Spatial lag") +
  ylab("Pair count") +
  theme(axis.text.x = element_text(angle = 45)) +
  scale_x_discrete(labels = df_hist$Breaks) +
  scale_y_continuous(breaks = c(0, 4, 6, 8, 10, 12))

histradius

# Create matrix of radius
rad_mat <- dist_mat
# Loop through radius and set distances in matrix
for (i in 2:length(radius)) {
  curr_radius <- radius[i]
  prev_radius <- radius[i - 1]
  rad_mat[dist_mat >= prev_radius & dist_mat < curr_radius] <- curr_radius
  rad_mat[dist_mat > curr_radius] <- Inf
}

rad_mat[dist_mat == 0] <- 0
# Make a triangle
rad_mat[lower.tri(rad_mat)] <- NA
# in km
rad_mat <- rad_mat / 1000 # change les resultats...
```

```{r}
# get the empirical chi
q <- 0.998
rain_new <- rain[-1]
rain_nozeros <- rain_new[rowSums(rain_new) > 0, ] #TODO verif ca 
rain_no_zeros <- df[!apply(df == 0, 1, any), ]

threshold <- quantile(rain_new$cnrs, probs = q, na.rm = T)

# get the quantile from threshold in the data without 0
empirical_cdf <- ecdf(rain_nozeros$cnrs)
quantile_in_nozeros <- empirical_cdf(threshold)

q <- 0.96
chispa <- spatial_chi(rad_mat, rain_nozeros, quantile = q)
spa_estim <- get_estimate_variospa(chispa, weights = "exp", summary = T)

tmax <- 10
q <- 0.96
chitemp <- temporal_chi(rain_new, tmax = tmax, quantile = q)
temp_estim <- get_estimate_variotemp(chitemp, tmax, npoints = ncol(rain),
                                      weights = "exp", summary = F)

df_result <- data.frame(beta1 =  spa_estim[1],
                        beta2 = temp_estim[1],
                        alpha1 = spa_estim[2],
                        alpha2 = temp_estim[2])

colnames(df_result) <- c("beta1", "alpha1", "beta2", "alpha2")

kable(df_result, format = "latex") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed",
  "responsive"), latex_options = "H")
```

# COMEPHORE

```{r}
setwd("./script")
# load data
df_comephore <- read.csv("../data/comephore/inside_mtp.csv", sep = ",")
loc_px <- read.csv("../data/comephore/loc_pixels_mtp.csv", sep = ",")
ncol(df_comephore)
comephore <- df_comephore[-1] # remove dates column
# Get distances matrix
dist_mat <- get_dist_mat(loc_px)
df_dist <- reshape_distances(dist_mat)
```

## Quantile

```{r}
comephore_nozeros <- comephore[rowSums(comephore) > 0, ]
df_no_zeros <- df[!apply(df == 0, 1, any), ]

# choose two site
comephore_pair <- comephore_nozeros[, c(1,10)]
chiplot(comephore_pair, xlim = c(0.85, 1), ylim1 = c(0.5, 1), which = 1,
        qlim = c(0.85, 0.999))
abline(v = 0.97, col = "red", lty = 2)

# count conjoint excesses
q <- 0.97
# uniformize the data
n <- nrow(comephore_pair)
data_unif <- cbind(rank(comephore_pair[, 1]) / (n + 1),
                          rank(comephore_pair[, 2]) / (n + 1))

count_excesses <- sum(data_unif[, 1] > q & data_unif[, 2] > q)
print(count_excesses)

comephore_pair <- comephore[, c(1,2)]
chiplot(comephore_pair, xlim = c(0.98, 1), ylim1 = c(0.5, 1), which = 1,
        qlim = c(0.98, 0.9995))

# threshold <- quantile(comephore$p102, probs = q, na.rm = T)

# get the quantile from threshold in the data without 0
# empirical_cdf <- ecdf(comephore_nozeros$p102)
# quantile_in_nozeros <- empirical_cdf(threshold)

rain_nolag <- comephore_nozeros$p142[1:(length(comephore_nozeros$p142) - 5)]
rain_lag <- comephore_nozeros$p142[6:length(comephore_nozeros$p142)]
comephore_pair <- cbind(rain_nolag, rain_lag)
chiplot(comephore_pair, xlim = c(0.9, 1), ylim1 = c(0, 1), which = 1,
        qlim = c(0.9, 0.995))
abline(v = 0.97, col = "red", lty = 2)

n <- nrow(comephore_pair)
data_unif <- cbind(rank(comephore_pair[, 1]) / (n + 1),
                          rank(comephore_pair[, 2]) / (n + 1))
q <- 0.97
count_excesses <- sum(data_unif[, 1] > q & data_unif[, 2] > q)
print(count_excesses)


q <- 0.97
```

## WLSE

```{r}
tmax <- 10
nsites <- length(loc_px$pixel_name)
# Temporal chi with spatial lag fixed at 0
# compute chiplot of every site with itself but lagged in time
start_time <- Sys.time()
chimat_dtlag <- temporal_chi(comephore_nozeros, quantile = q, tmax = tmax,
                             mean = FALSE)
end_time <- Sys.time()
elapsed_time <- end_time - start_time
print(elapsed_time)
```

```{r}
par(mfrow = c(1, 1))
chi_df_dt <- data.frame(chimat_dtlag)
colnames(chi_df_dt) <- c(1:tmax) # temporal lags from 1 to tmax
rownames(chi_df_dt) <- c(1:nsites) # stations

# remove 0
q <- 0.9
chimat_dt_mean <- temporal_chi(comephore_nozeros, tmax, quantile = q,
                               mean = TRUE)
# get h axis in minutes ie x5 minutes
df <- data.frame(lag = c(1:tmax), chi = chimat_dt_mean)
ggplot(df, aes(x = lag, y = chi)) +
  geom_point(color = btfgreen) +
  btf_theme +
  xlab("Temporal lag") +
  ylab(TeX(r"($\hat{\chi}$)"))

wlse_temp <- get_estimate_variotemp(chimat_dt_mean, tmax, nsites,
                                    weights = "exp", summary = T)

print(wlse_temp)
alpha2 <- wlse_temp[[2]]
beta2 <- wlse_temp[[1]]
c2 <- log(beta2)

dftemp <- data.frame(lag = log(df$lag), chi = eta(df$chi))

chitemp_eta_estim <- ggplot(dftemp, aes(x = lag, y = chi)) +
  geom_point(color = btfgreen, size = 4) +
  btf_theme +
  xlab(TeX(r"($\log(\tau)$)")) +
  ylab(TeX(r"($\eta(\widehat{\chi}(0,\tau))$)")) +
  geom_line(aes(x = lag, y = alpha2 * lag + c2),
            alpha = 0.6, color = "darkred", linewidth = 1.5)

chitemp_eta_estim
```


```{r}
# Spatial chi ------------------------------------------------------------------
df_dist$value <- ceiling(df_dist$value / 100) * 100  # / 1000 in km
df_dist_km <- df_dist
df_dist_km$value <- df_dist$value / 1000

q <- 0.97
chispa_df <- spatial_chi_alldist(df_dist_km, data_rain = comephore_nozeros,
                                 quantile = q, hmax = 6)

etachispa_df <- data.frame(chi = eta(chispa_df$chi),
                           lagspa = log(chispa_df$lagspa))

chispa_plot <- ggplot(chispa_df, aes(lagspa, chi)) +
  btf_theme +
  geom_point(col = btfgreen, size = 4) +
  xlab(TeX(r"($h$)")) +
  ylab(TeX(r"($\widehat{\chi}(h, 0)$)")) +
  theme(axis.ticks = element_blank(),
        axis.line = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15),
        legend.position = "right",
        legend.margin = margin(0.5, 0.5, 0.5, 0, "cm"),
        panel.grid = element_line(color =  "#5c595943")) +
  ylim(0, 1)

chispa_plot

# WLSE
wlse_spa <- get_estimate_variospa(chispa_df, weights = "exp", summary = T)

alpha1 <- wlse_spa[[2]]
beta1 <- wlse_spa[[1]]
c1 <- log(beta1)

chispa_eta_estim <- ggplot(etachispa_df, aes(lagspa, chi)) +
  btf_theme +
  geom_point(col = btfgreen, size = 4) +
  xlab(TeX(r"($\log(h)$)")) +
  ylab(TeX(r"($\eta(\widehat{\chi}(h, 0))$)")) +
  theme(axis.ticks = element_blank(),
        axis.line = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 15),
        legend.title = element_text(size = 15),
        legend.position = "right",
        legend.margin = margin(0.5, 0.5, 0.5, 0, "cm"),
        panel.grid = element_line(color = "#5c595943")) +
  geom_line(aes(x = lagspa, y = alpha1 * lagspa + c1), alpha = 0.6,
            color = "darkred", linewidth = 1.5)

chispa_eta_estim

df_result <- data.frame(beta1 =  beta1,
                        beta2 = beta2,
                        alpha1 = alpha1,
                        alpha2 = alpha2)

colnames(df_result) <- c("beta1", "alpha1", "beta2", "alpha2")

kable(df_result, format = "latex") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed",
  "responsive"), latex_options = "H")
```

## Optimisation

```{r}
# Get coords
sites_coords <- loc_px[, c("Longitude", "Latitude")]

# Function to choose conditional points
choose_conditional_points <- function(sites_coords, data, quantile, 
                                      min_spatial_dist, min_time_dist) {
  # Ensure the quantile is within range
  if (quantile < 0 || quantile > 1) {
    stop("Quantile must be between 0 and 1.")
  }

  # Uniformize the data
  data_unif <- data
  for (i in 1:ncol(data)) {
    data_unif[, i] <- rank(data[, i]) / (nrow(data) + 1)
  }

  # Identify valid (site, time) where X_s,t > quantile
  valid_indices <- which(as.matrix(data_unif) > quantile, arr.ind = TRUE)

  if (nrow(valid_indices) == 0) {
    stop("No points exceed the given quantile for any time step.")
  }

  # Initialize the selected points
  selected_points <- list()

  # Variable to store the last selected point
  last_selected <- NULL

  # Iterate over valid indices to select points
  for (i in seq_len(nrow(valid_indices))) {
    current_index <- valid_indices[i, ] # Current index (time, site)
    current_point <- list(
      s0 = sites_coords[current_index[2], ],
      t0 = as.numeric(current_index[1])
    )

    if (is.null(last_selected)) {
      selected_points <- append(selected_points, list(current_point))
      last_selected <- current_point # Update last selected point
    } else {
      # Check if this point is valid given previously selected points
      # and the minimum spatial and time distances
      dist_spa <- distHaversine(current_point$s0, last_selected$s0) / 1000
      dist_time <- abs(current_point$t0 - last_selected$t0)
      if (dist_spa >= min_spatial_dist && dist_time >= min_time_dist) {
        selected_points <- append(selected_points, list(current_point))
        last_selected <- current_point  # Update last selected point
      }
    }
  }

  if (length(selected_points) == 0) {
    stop("No spatio-temporal points satisfy the quantile, the minimum spatial 
          and time distances.")
  }

  return(selected_points)
}

# remove 0
rain_new <- comephore
quantile <- 0.95
min_spatial_dist <- 2 # in km
min_time_dist <- 5 # in hours

selected_points <- choose_conditional_points(
  sites_coords = sites_coords,
  data = rain_new,
  quantile = quantile,
  min_spatial_dist = min_spatial_dist,
  min_time_dist = min_time_dist
)

# Extract s0 and t0
s0_list <- lapply(selected_points, `[[`, "s0")
t0_list <- lapply(selected_points, `[[`, "t0")


library(parallel)

# Get lags and excesses for each conditional point
list_results <- mclapply(1:length(s0_list), function(i) {
  s0 <- s0_list[[i]]
  t0 <- t0_list[[i]]
  lags <- get_conditional_lag_vectors(sites_coords, s0, t0, tau_max = 100,
                                      latlon = TRUE)
  lags$hx <- lags$hx / 1000  # in km
  lags$hy <- lags$hy / 1000  # in km
  lags$hnorm <- lags$hnorm / 1000  # in km
  excesses <- empirical_excesses(rain_new, q, lags, type = "rpareto")
  list(lags = lags, excesses = excesses)
}, mc.cores = detectCores() - 1)

# Extract list_lags from list_results
list_lags <- lapply(list_results, `[[`, "lags")

# Extract list_excesses from list_results
list_excesses <- lapply(list_results, `[[`, "excesses")


neg_ll_composite_rpar <- function(params, data, list_lags, quantile,
                    list_excesses, hmax = NA, s0_list = NA,
                    t0_list = NA, threshold = FALSE) {
  print(params)
  # Bounds for the parameters
  lower.bound <- c(1e-8, 1e-8, 1e-8, 1e-8)
  upper.bound <- c(Inf, Inf, 1.999, 1.999)
  if (length(params) == 6) {
    lower.bound <- c(lower.bound, -Inf, -Inf)
    upper.bound <- c(upper.bound, Inf, Inf)
  }

  # Check if the parameters are in the bounds
  if (any(params < lower.bound) || any(params > upper.bound)) {
    return(1e50)
  }

  m <- length(list_excesses) # number of r-pareto processes
  nll_composite <- 0 # composite negative log-likelihood
  for (i in 1:m) {
    # extract lags and excesses from i-th r-pareto process from data
    df_lags <- list_lags[[i]]
    excesses <- list_excesses[[i]]
    s0 <- s0_list[[i]]
    t0 <- t0_list[[i]]
    nll_i <- neg_ll(params, data, df_lags, quantile, hmax = hmax,
                    excesses = excesses, s0 = s0, t0 = t0,
                    threshold = threshold)
    nll_composite <- nll_composite + nll_i
  }
  return(nll_composite) # multiply by 100 to avoid numerical issues?
}

init_param <- c(beta1, beta2, alpha1, alpha2, 0.01, 0.1)

result <- optim(par = init_param, fn = neg_ll_composite_rpar,
        data = rain_new, quantile = quantile, list_lags = list_lags,
        list_excesses = list_excesses, hmax = 7, s0_list = s0_list,
        t0_list = t0_list, threshold = FALSE,
        method = "L-BFGS-B",
        lower = c(1e-08, 1e-08, 1e-08, 1e-08, -Inf, -Inf),
        upper = c(Inf, Inf, 1.999, 1.999, Inf, Inf),
        control = list(maxit = 10000),
        hessian = TRUE)
result$par
# Check the convergence
if (result$convergence != 0) {
  warning("The optimization did not converge.")
}

# Extract the results
df_result <- data.frame(beta1 =  result$par[1],
                        beta2 = result$par[2],
                        alpha1 = result$par[3],
                        alpha2 = result$par[4],
                        adv1 = result$par[5],
                        adv2 = result$par[6])

# Get the hessian
hessian <- result$hessian
cov_matrix <- solve(hessian)

eigenvalues <- eigen(hessian)$values
if (any(eigenvalues <= 0)) {
  stop("Hessian matrix is not positive definite.")
}

# eigen_decomp <- eigen(hessian)
# eigenvalues <- eigen_decomp$values
# eigenvectors <- eigen_decomp$vectors

# tol <- 1e-6
# eigenvalues[eigenvalues <= tol] <- tol

# hessian_reg <- eigenvectors %*% diag(eigenvalues) %*% t(eigenvectors)

# cov_matrix <- solve(hessian_reg)
# se <- sqrt(diag(cov_matrix))
# conf_int <- cbind(result$par - 1.96 * se, result$par + 1.96 * se)

```


### Variogram

```{r}
# compute variogram with parameters
tau_values <- c(0, 3, 5, 10)
result <- df_result
df_lags <- list_lags[[5]]
generate_variogram_plots(result, df_lags, init_param, tau_values, chi=F)
```

### Notes 

