---
title: "Optimisation"
author: " "
date: "`r Sys.Date()`" 
output:
  pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 5, fig.height = 5,
                      fig.align = 'center', message = FALSE, warning = FALSE,
                      fig.pos='H', echo=FALSE)

```


```{r lib, echo=FALSE}
# setwd("./script")
library(generain)
library(reshape2)
library(ggplot2)
source("load_libraries.R")
library(kableExtra)
library(extRemes)
library(bbmle)
library(ismev)
library(extRemes)
library(evd)
library(dplyr)
library(latex2exp)

btf_theme <- theme_minimal() +
  theme(axis.text.x = element_text(size =  6, angle = 0),
        axis.text.y = element_text(size = 6),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.text = element_text(size = 6),
        title = element_text(size = 10),
        axis.line = element_blank(),  # Remove axis lines
        panel.border = element_blank(),  # Remove plot border
        panel.background = element_rect(fill = "transparent", color = NA),
        # Remove plot background
        axis.text = element_blank(),  # Remove axis text
        axis.ticks = element_blank(),  # Remove axis ticks
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.grid = element_line(color = "#5c595943"))

# my green color
btfgreen <- "#69b3a2"

# setwd("./script")
```


# The $r$-Pareto process without advection and new params

## Simulation

We simulate the $r$-Pareto process with the parameters $\beta_1 = 0.5$,
$\beta_2 = 0.1$, $\alpha_1 = 1.2$, $\alpha_2 = 0.9$ and the advection vector
$V = (0.5, 0.3)$. We simulate the process on a $5 \times 5$ grid with
$30$ time steps and $100$ realizations. We use a conditonal point $s_0 = (1, 1)$ at
time $t_0 = 1$.

```{r rparetosim1, fig.width = 5, fig.height = 5, echo=FALSE, fig.cap="Time series for 4 sites of the first realization in the advection direction"}
adv <- c(0, 0) # advection
params <- c(0.5, 0.3, 1.5, 1) # ok verif sur simu
true_param <- c(params, adv)
beta1 <- params[1]
beta2 <- params[2]
alpha1 <- params[3]
alpha2 <- params[4]
ngrid <- 5
spa <- 1:ngrid
nsites <- ngrid^2 # if the grid is squared
temp <- 1:100

# Conditional point
s0 <- c(1, 1)
t0 <- 1

# Number of realizations
M <- 10
m <- 100
nres <- M * m

# Simulate the process
simu <- sim_rpareto(beta1, beta2, alpha1, alpha2, spa, spa, temp, adv, s0,
                    t0, nres)

if (any(adv < 1 && adv > 0.1)) {
  adv_int <- adv * 10
  adv_str <- sprintf("%02d_%02d", adv_int[1], adv_int[2])
} else if (adv < 0.1 && adv > 0) {
  adv_int <- adv * 100
  adv_str <- sprintf("%03d_%03d", adv_int[1], adv_int[2])
} else {
  adv_int <- adv
  adv_str <- sprintf("%02d_%02d", adv_int[1], adv_int[2])
}

param_str <- sprintf("%02d_%02d_%02d_%02d", true_param[1] * 10,
                    true_param[2] * 10, true_param[3] * 10, true_param[4] * 10)

# Save the data
foldername <- paste0("../data/simulations_rpar_", param_str,"/sim_", ngrid^2, 
                    "s_", length(temp), "t_", adv_str, "/")


if (!dir.exists(foldername)) {
  dir.create(foldername, recursive = TRUE)
}

save_simulations(simu, ngrid, nres, folder = foldername,
        file = paste0("rpar_", ngrid^2, "s_", length(temp), "t"))

# nres <- length(list.files(foldername))
list_simu <- list() # first simulation of m replicates
for (i in 1:m) {
  file_name <- paste0(foldername, "rpar_", ngrid^2, "s_",
                        length(temp), "t_", i, ".csv")
  list_simu[[i]] <- read.csv(file_name)
}

list_simuM <- list()
for (i in 1:nres) {
  file_name <- paste0(foldername, "rpar_", ngrid^2, "s_",
                        length(temp), "t_", i, ".csv")
  list_simuM[[i]] <- read.csv(file_name)
}

# Plot the first realization
simu_df <- list_simu[[2]]
sites_coords <- generate_grid_coords(ngrid)
```

## Optimisation

We want to estimate the parameters $\beta_1$, $\beta_2$, $\alpha_1$ and $\alpha_2$
of the $r$-Pareto process. We use the maximum likelihood estimation with the
composite likelihood method. 

We compute the number of joint excesses for each replicate $i$,  $k^{(i)}_{s, t} = \sum_{t=1}^T \mathbb{1}_{\{X_{s, t} > u, X_{s_0, t_0} > u\}}$
and $k^{(i)}_{s-s_0, t-t_0} \sim Bin(T - t - t_0, \chi(s - s_0, t - t_0))$ with $T$ the number of observations
within a replicate (same for all replicates).


```{r optimrparadv, fig.width = 5, fig.height = 5, echo=FALSE}
sites_coords <- generate_grid_coords(ngrid)
df_lags <- get_conditional_lag_vectors(sites_coords, s0, t0, tau_max = 10)

u <- 1
list_excesses <- list()
# par(mfrow=c(5, 2))
for (i in 1:m) {
  list_excesses[[i]] <- empirical_excesses(list_simu[[i]], u, df_lags,
                                     threshold = TRUE, type="rpareto", t0=1)
}

result <- optim(par = true_param, fn = neg_ll_composite,
                  list_simu = list_simu,
                  quantile = u,
                  df_lags = df_lags,
                  list_excesses = list_excesses,
                  hmax = sqrt(17),
                  s0 = s0,
                  t0 = t0,
                  threshold = TRUE,
                  method = "L-BFGS-B",
                  lower = c(1e-6, 1e-6, 1e-6, 1e-6, -Inf, -Inf),
                  upper = c(Inf, Inf, 1.999, 1.999, Inf, Inf),
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000))


df_result <- data.frame(beta1 =  result$par[1],
                        beta2 = result$par[2],
                        alpha1 = result$par[3],
                        alpha2 = result$par[4],
                        adv1 = result$par[5],
                        adv2 = result$par[6])

# df_rmse <- data.frame(beta1 = sqrt((result$par[1] - true_param[1])^2),
#                 beta2 = sqrt((result$par[2] - true_param[2])^2),
#                 alpha1 = sqrt((result$par[3] - true_param[3])^2),
#                 alpha2 = sqrt((result$par[4] - true_param[4])^2),
#                 adv1 = sqrt((result$par[5] - true_param[5])^2),
#                 adv2 = sqrt((result$par[6] - true_param[6])^2))

# df_result <- rbind(df_result, df_rmse)
# rownames(df_result) <- c("estim", "rmse")

# save the result
foldername <- "../data/optim/rpar_adv/"
if (!dir.exists(foldername)) {
  dir.create(foldername, recursive = TRUE)
}


name_file <- paste0("result_optim_", nres, "simu_", ngrid^2,
                                "s_", length(temp), "t_", adv_str, ".csv")

# write.csv(df_result, paste0(foldername, name_file))

# get csv
df_result <- read.csv(paste0(foldername, name_file))
kable(df_result, "latex", booktabs = TRUE,
        caption = "Result and RMSE for all replicates together with advection=(0.5,0.3) with tau=0:10")  %>%
    kable_styling(latex_options = "H",
        bootstrap_options = c("striped", "hover", "condensed", "responsive"))

name_file_tau5 <- paste0("result_optim_tau5_", m, "simu_", ngrid^2,
                                "s_", length(temp), "t_", adv_str, ".csv")

# write.csv(df_result, paste0(foldername, name_file_tau5))

df_result_tau5 <- read.csv(paste0(foldername, name_file_tau5))
kable(df_result_tau5, "latex", booktabs = TRUE,
        caption = "Result and RMSE for all replicates together with advection=(0.5,0.3) with tau=0:5")  %>%
    kable_styling(latex_options = "H",
        bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

```{r rparetosim2, fig.width = 5, fig.height = 5, echo=FALSE, fig.cap="Time series for 4 sites of the first realization in the advection direction"}
df_lags <- get_conditional_lag_vectors(sites_coords, true_param, temp, s0, t0,
                                      tau_max = 10)

df_result_all <- data.frame(beta1 = numeric(M),
                        beta2 = numeric(M),
                        alpha1 = numeric(M),
                        alpha2 = numeric(M),
                        adv1 = numeric(M),
                        adv2 = numeric(M))
u <- 1

for (i in 1:M){
  # get the m corresponding simulations from list_simu inside a list
  mreplicates <- list_simuM[((i - 1) * m + 1):(i * m)]

  list_excesses <- list()
  for (j in 1:m) {
    replicate <- mreplicates[[j]]
    list_excesses[[j]] <- empirical_excesses_rpar(replicate, u, df_lags,
                                            threshold = TRUE, t0=t0)
  }

  result <- optim(par = true_param, fn = neg_ll_composite,
                  list_simu = mreplicates,
                  quantile = u,
                  df_lags = df_lags,
                  list_excesses = list_excesses,
                  hmax = sqrt(17),
                  s0 = s0,
                  t0 = t0,
                  threshold = TRUE,
                  method = "L-BFGS-B",
                  lower = c(1e-6, 1e-6, 1e-6, 1e-6, -Inf, -Inf),
                  upper = c(Inf, Inf, 1.999, 1.999, Inf, Inf),
                  control = list(parscale = c(1, 1, 1, 1, 1, 1),
                                 maxit = 10000,
                                 ndeps = c(1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 1e-3)))
  df_result_all[i, ] <- result$par

}

```